{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory containing CSV files\n",
    "csv_directory_path = r\"E:\\Code\\data_blog\\blog_files\\data\"\n",
    "\n",
    "# List all files in the directory\n",
    "all_files = os.listdir(csv_directory_path)\n",
    "specific_csv_files = [f for f in all_files if f.endswith('.csv')]\n",
    "\n",
    "# Create a list of full file paths for the specific CSV files\n",
    "specific_csv_paths = [os.path.join(csv_directory_path, f) for f in specific_csv_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dictionary with default lists\n",
    "file_categories = defaultdict(list)\n",
    "\n",
    "# Categorize filenames\n",
    "for filename in specific_csv_files:\n",
    "    if 'biometrics' in filename.lower():\n",
    "        file_categories['biometrics'].append(os.path.join(csv_directory_path, filename))\n",
    "    elif 'dailysummary' in filename.lower():\n",
    "        file_categories['dailysummary'].append(os.path.join(csv_directory_path, filename))\n",
    "    elif 'servings' in filename.lower():\n",
    "        file_categories['servings'].append(os.path.join(csv_directory_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'biometrics': ['E:\\\\Code\\\\data_blog\\\\blog_files\\\\data\\\\biometrics.csv'],\n",
       "             'dailysummary': ['E:\\\\Code\\\\data_blog\\\\blog_files\\\\data\\\\dailysummary.csv'],\n",
       "             'servings': ['E:\\\\Code\\\\data_blog\\\\blog_files\\\\data\\\\servings.csv']})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\Code\\\\data_blog\\\\blog_files\\\\data\\\\biometrics.csv',\n",
       " 'E:\\\\Code\\\\data_blog\\\\blog_files\\\\data\\\\dailysummary.csv',\n",
       " 'E:\\\\Code\\\\data_blog\\\\blog_files\\\\data\\\\servings.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_csv_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(specific_csv_paths[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Day', 'Group', 'Food Name', 'Amount', 'Energy (kcal)', 'Alcohol (g)',\n",
       "       'Caffeine (mg)', 'Water (g)', 'B1 (Thiamine) (mg)',\n",
       "       'B2 (Riboflavin) (mg)', 'B3 (Niacin) (mg)',\n",
       "       'B5 (Pantothenic Acid) (mg)', 'B6 (Pyridoxine) (mg)',\n",
       "       'B12 (Cobalamin) (µg)', 'Folate (µg)', 'Vitamin A (µg)',\n",
       "       'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (mg)', 'Vitamin K (µg)',\n",
       "       'Calcium (mg)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)',\n",
       "       'Manganese (mg)', 'Phosphorus (mg)', 'Potassium (mg)', 'Selenium (µg)',\n",
       "       'Sodium (mg)', 'Zinc (mg)', 'Carbs (g)', 'Fiber (g)', 'Starch (g)',\n",
       "       'Sugars (g)', 'Added Sugars (g)', 'Net Carbs (g)', 'Fat (g)',\n",
       "       'Cholesterol (mg)', 'Monounsaturated (g)', 'Polyunsaturated (g)',\n",
       "       'Saturated (g)', 'Trans-Fats (g)', 'Omega-3 (g)', 'Omega-6 (g)',\n",
       "       'Cystine (g)', 'Histidine (g)', 'Isoleucine (g)', 'Leucine (g)',\n",
       "       'Lysine (g)', 'Methionine (g)', 'Phenylalanine (g)', 'Protein (g)',\n",
       "       'Threonine (g)', 'Tryptophan (g)', 'Tyrosine (g)', 'Valine (g)',\n",
       "       'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform a single column name\n",
    "def transform_column_name(col_name):\n",
    "    col_name = col_name.lower()\n",
    "    col_name = re.sub(r' ', '_', col_name)\n",
    "    col_name = re.sub(r'[^a-z0-9_]', '', col_name)\n",
    "    if not re.match(r'^[a-z_]', col_name):\n",
    "        col_name = f'_{col_name}'\n",
    "    col_name = col_name[:128]\n",
    "    return col_name\n",
    "\n",
    "new_column_names = [transform_column_name(col) for col in df.columns]\n",
    "df.columns = new_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day', 'group', 'food_name', 'amount', 'energy_kcal', 'alcohol_g',\n",
       "       'caffeine_mg', 'water_g', 'b1_thiamine_mg', 'b2_riboflavin_mg',\n",
       "       'b3_niacin_mg', 'b5_pantothenic_acid_mg', 'b6_pyridoxine_mg',\n",
       "       'b12_cobalamin_g', 'folate_g', 'vitamin_a_g', 'vitamin_c_mg',\n",
       "       'vitamin_d_iu', 'vitamin_e_mg', 'vitamin_k_g', 'calcium_mg',\n",
       "       'copper_mg', 'iron_mg', 'magnesium_mg', 'manganese_mg', 'phosphorus_mg',\n",
       "       'potassium_mg', 'selenium_g', 'sodium_mg', 'zinc_mg', 'carbs_g',\n",
       "       'fiber_g', 'starch_g', 'sugars_g', 'added_sugars_g', 'net_carbs_g',\n",
       "       'fat_g', 'cholesterol_mg', 'monounsaturated_g', 'polyunsaturated_g',\n",
       "       'saturated_g', 'transfats_g', 'omega3_g', 'omega6_g', 'cystine_g',\n",
       "       'histidine_g', 'isoleucine_g', 'leucine_g', 'lysine_g', 'methionine_g',\n",
       "       'phenylalanine_g', 'protein_g', 'threonine_g', 'tryptophan_g',\n",
       "       'tyrosine_g', 'valine_g', 'category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 675 entries, 0 to 674\n",
      "Data columns (total 57 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   day                     675 non-null    object \n",
      " 1   group                   675 non-null    object \n",
      " 2   food_name               675 non-null    object \n",
      " 3   amount                  675 non-null    object \n",
      " 4   energy_kcal             653 non-null    float64\n",
      " 5   alcohol_g               373 non-null    float64\n",
      " 6   caffeine_mg             420 non-null    float64\n",
      " 7   water_g                 465 non-null    float64\n",
      " 8   b1_thiamine_mg          456 non-null    float64\n",
      " 9   b2_riboflavin_mg        452 non-null    float64\n",
      " 10  b3_niacin_mg            452 non-null    float64\n",
      " 11  b5_pantothenic_acid_mg  401 non-null    float64\n",
      " 12  b6_pyridoxine_mg        421 non-null    float64\n",
      " 13  b12_cobalamin_g         394 non-null    float64\n",
      " 14  folate_g                432 non-null    float64\n",
      " 15  vitamin_a_g             431 non-null    float64\n",
      " 16  vitamin_c_mg            436 non-null    float64\n",
      " 17  vitamin_d_iu            402 non-null    float64\n",
      " 18  vitamin_e_mg            371 non-null    float64\n",
      " 19  vitamin_k_g             369 non-null    float64\n",
      " 20  calcium_mg              506 non-null    float64\n",
      " 21  copper_mg               399 non-null    float64\n",
      " 22  iron_mg                 502 non-null    float64\n",
      " 23  magnesium_mg            433 non-null    float64\n",
      " 24  manganese_mg            399 non-null    float64\n",
      " 25  phosphorus_mg           420 non-null    float64\n",
      " 26  potassium_mg            437 non-null    float64\n",
      " 27  selenium_g              381 non-null    float64\n",
      " 28  sodium_mg               647 non-null    float64\n",
      " 29  zinc_mg                 445 non-null    float64\n",
      " 30  carbs_g                 669 non-null    float64\n",
      " 31  fiber_g                 588 non-null    float64\n",
      " 32  starch_g                370 non-null    float64\n",
      " 33  sugars_g                639 non-null    float64\n",
      " 34  added_sugars_g          383 non-null    float64\n",
      " 35  net_carbs_g             669 non-null    float64\n",
      " 36  fat_g                   675 non-null    float64\n",
      " 37  cholesterol_mg          585 non-null    float64\n",
      " 38  monounsaturated_g       406 non-null    float64\n",
      " 39  polyunsaturated_g       406 non-null    float64\n",
      " 40  saturated_g             624 non-null    float64\n",
      " 41  transfats_g             584 non-null    float64\n",
      " 42  omega3_g                406 non-null    float64\n",
      " 43  omega6_g                399 non-null    float64\n",
      " 44  cystine_g               410 non-null    float64\n",
      " 45  histidine_g             410 non-null    float64\n",
      " 46  isoleucine_g            410 non-null    float64\n",
      " 47  leucine_g               410 non-null    float64\n",
      " 48  lysine_g                410 non-null    float64\n",
      " 49  methionine_g            410 non-null    float64\n",
      " 50  phenylalanine_g         410 non-null    float64\n",
      " 51  protein_g               670 non-null    float64\n",
      " 52  threonine_g             410 non-null    float64\n",
      " 53  tryptophan_g            411 non-null    float64\n",
      " 54  tyrosine_g              410 non-null    float64\n",
      " 55  valine_g                410 non-null    float64\n",
      " 56  category                519 non-null    object \n",
      "dtypes: float64(52), object(5)\n",
      "memory usage: 300.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql, connect, OperationalError, errorcodes, errors\n",
    "import sys\n",
    "class DatabaseManager:\n",
    "    \"\"\"\n",
    "    A class to manage database connections using psycopg2.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    conn : psycopg2 connection object\n",
    "        connection to the database to handle database actions\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    create_tables():\n",
    "        Creates the `parameters` and `blendermann_coefficients` tables for the database.\n",
    "\n",
    "    create_entry(table_name, fields, values):\n",
    "        Creates an entry in the table given the values and fields to insert them into.\n",
    "    \n",
    "    update_value(table_name, fields, entry):\n",
    "        Updates a specified entry in the database given the fields and entry details.\n",
    "    \n",
    "    get_table(table_name):\n",
    "        Obtains all the entries of a table when given the table name.\n",
    "\n",
    "    get_value(table_name, fields, values):\n",
    "        Runs a select statement, filtering the values by supplying the WHERE clause of the SQL query using the provided fields and values.\n",
    "    \n",
    "    delete_value(table_name, fields, values):\n",
    "        Deletes the entries of a table in the database given the fields and their corresponding values.\n",
    "\n",
    "    get_fields(table_name):\n",
    "        Returns the fields of the database table given the table name.\n",
    "\n",
    "    get_table_desc(table_name):\n",
    "        Returns a tuple of the fields as well as their type codes.\n",
    "    \n",
    "    insert_dataframe(table_name, df):\n",
    "        Inserts a pandas dataframe as a series of INSERT statements into the database table table_name\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, user, dbname, password, host, port):\n",
    "        \"\"\"\n",
    "        Constructs a database connection using the provided parameters.\n",
    "        Configured in the provided .env file, can be manually set as well by calling an instance of the manager as DatabaseManager(user, dbname, password, host, port)\n",
    "\n",
    "        ...\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            user : str\n",
    "                username credentials of the database\n",
    "            dbname : str\n",
    "                name of the database to request access to\n",
    "            password : str\n",
    "                password credentials of the database\n",
    "            host : str\n",
    "                host address of the database\n",
    "            port : str\n",
    "                port address of the database\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        True: if the database was connected\n",
    "        False: if the database was not connected\n",
    "        \"\"\"\n",
    "        connection_string = f'user={user} dbname={dbname} password={password} host={host} port={port}'\n",
    "\n",
    "        try:\n",
    "            self.conn = psycopg2.connect(connection_string)\n",
    "            print('Database manager has connected to ' + str(dbname)) # Logging to stdout\n",
    "        except Exception as err:\n",
    "            self.print_psycopg2_exception(err)\n",
    "            self.conn = None\n",
    "\n",
    "    def create_entry(self, table_name, fields, values):\n",
    "        \"\"\"\n",
    "        Creates an entry in the database\n",
    "\n",
    "        ...\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        table_name: str\n",
    "            database table to insert the entry into\n",
    "        fields: tuple\n",
    "            list of fields to insert the entry into\n",
    "        values: tuple\n",
    "            list of values per specfied field of the entry\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        True: if the entry was created\n",
    "        False: if the entry was not created\n",
    "        \"\"\"\n",
    "\n",
    "        cur = self.conn.cursor()\n",
    "        \n",
    "        # check if entry is present before inserting\n",
    "        column_names, rows = self.get_value(table_name, fields, values)\n",
    "        if len(rows) >= 1:\n",
    "            print('Entry already exists. Insertion is not continued.')\n",
    "            return False\n",
    "\n",
    "        # query for inserting values\n",
    "        query = sql.SQL(\"\"\"\n",
    "        INSERT INTO {table} ({fields})\n",
    "        VALUES ({values})\n",
    "        \"\"\").format(\n",
    "            table=sql.Identifier(table_name),\n",
    "            fields=sql.SQL(', ').join(map(sql.Identifier, fields)),\n",
    "            values=sql.SQL(', ').join(sql.Placeholder() * len(values))\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            cur.execute(query, values)\n",
    "            self.conn.commit()\n",
    "            print('Entry insertion of `ship_id:' + values[0] + '` complete') # Logging to stdout\n",
    "        except Exception as err:\n",
    "            self.print_psycopg2_exception(err)\n",
    "            self.conn.rollback()\n",
    "            return False\n",
    "        cur.close()\n",
    "        return True\n",
    "\n",
    "    def update_value(self, table_name, fields, entry):\n",
    "        \"\"\"\n",
    "        Updates an entry given a primary key.\n",
    "\n",
    "        ...\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        table_name: str\n",
    "            database table that contains the entry\n",
    "        fields: tuple\n",
    "            list of fields to update the entry to\n",
    "            first element is assumed to be the primary key\n",
    "        values: tuple\n",
    "            list of values to update the entry to\n",
    "            first element is assumed to be the primary key\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        True: if the entry was updated\n",
    "        False: if the entry was not updated\n",
    "        \"\"\"\n",
    "\n",
    "        cur = self.conn.cursor()\n",
    "        pk_value = entry[0]\n",
    "        new_values = entry[1:]\n",
    "\n",
    "        # query for updating values from table\n",
    "        set_clause = sql.SQL(', ').join(\n",
    "            sql.SQL(\"{field} = %s\").format(field=sql.Identifier(field))\n",
    "            for field in fields[1:]\n",
    "        )\n",
    "        where_clause = sql.SQL(\"{pk_field} = %s\").format(pk_field=sql.Identifier(fields[0]))\n",
    "\n",
    "        query = sql.SQL(\"\"\"\n",
    "        UPDATE {table}\n",
    "        SET {set_clause}\n",
    "        WHERE {where_clause}\n",
    "        \"\"\").format(\n",
    "            table=sql.Identifier(table_name),\n",
    "            set_clause=set_clause,\n",
    "            where_clause=where_clause\n",
    "        )\n",
    "\n",
    "        values = new_values + [pk_value]\n",
    "\n",
    "        try:\n",
    "            cur.execute(query, values)\n",
    "            self.conn.commit()\n",
    "            print(str(pk_value) + ' updated to new values: ' + str(entry) + '.') # Logging to stdout\n",
    "        except Exception as err:\n",
    "            self.print_psycopg2_exception(err)\n",
    "            self.conn.rollback()\n",
    "            return False\n",
    "        cur.close()\n",
    "        return True\n",
    "\n",
    "    def get_table(self, table_name):\n",
    "        \"\"\"\n",
    "        Returns the rows of a table as a mutable object.\n",
    "\n",
    "        ...\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        table_name: str\n",
    "            name of the database table to retrieve entries from\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        column_names: list or None\n",
    "            list is returned if no error occurred, None otherwise\n",
    "        rows: list or None\n",
    "            list is returned if no error occurred, None otherwise\n",
    "        \"\"\"\n",
    "        cur = self.conn.cursor()\n",
    "\n",
    "        # query for reading from table\n",
    "        query = sql.SQL(\"\"\"\n",
    "        SELECT * FROM {table}\n",
    "        \"\"\").format(\n",
    "            table=sql.Identifier(table_name)\n",
    "        )\n",
    "        try:\n",
    "            cur.execute(query, table_name)\n",
    "            rows = cur.fetchall()\n",
    "            column_names = [desc[0] for desc in cur.description]\n",
    "            print('Fetched ' + str(len(rows)) + ' entries from ' + table_name) # Logging to stdout\n",
    "            cur.close()\n",
    "            return column_names, rows\n",
    "        except Exception as err:\n",
    "            self.print_psycopg2_exception(err)\n",
    "            self.conn.rollback()\n",
    "            return None, None\n",
    "        \n",
    "    def get_value(self, table_name, fields, values):\n",
    "        \"\"\"\n",
    "        Gets values from the database table given a set of fields and values to search from\n",
    "        Note that the template for obtaining the value only works for fields that have one value, i.e. primary key fields such as `ship_id` or `vessel_type`\n",
    "        The template for obtaining values within an array or timestamp will vary and need to be created in a separate function if needed\n",
    "        ...\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        table_name: str\n",
    "            name of the database table to retrieve entries from\n",
    "        fields: tuple\n",
    "            list of fields to find entry\n",
    "        values: tuple\n",
    "            list of values to find entry\n",
    "        Returns\n",
    "        ----------\n",
    "        column_name, rows: list or None\n",
    "            returns mutable objects for both variables if elements that follow the conditions were found, None otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        cur = self.conn.cursor()\n",
    "\n",
    "        # query for selecting with set values\n",
    "        where_clause = sql.SQL(' AND ').join(\n",
    "            sql.SQL(\"{field} = %s\").format(field=sql.Identifier(field))\n",
    "            for field in fields\n",
    "        )\n",
    "        query = sql.SQL(\"\"\"\n",
    "        SELECT * FROM {table}\n",
    "        WHERE {where_clause}\n",
    "        \"\"\").format(\n",
    "            table=sql.Identifier(table_name),\n",
    "            where_clause=where_clause\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            cur.execute(query, values)\n",
    "            rows = cur.fetchall()\n",
    "            column_names = [desc[0] for desc in cur.description]\n",
    "            print('Fetched ' + str(len(rows)) + ' entries from ' + table_name) # Logging to stdout\n",
    "        except Exception as err:\n",
    "            self.print_psycopg2_exception(err)\n",
    "            self.conn.rollback()\n",
    "            return None, None\n",
    "        cur.close()\n",
    "        return column_names, rows\n",
    "\n",
    "    def delete_value(self, table_name, fields, values):\n",
    "        \"\"\"\n",
    "        Deletes values from the database table\n",
    "\n",
    "        ...\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        table_name: str\n",
    "            name of the database table to retrieve entries from\n",
    "        fields: tuple\n",
    "            list of fields to find entry to delete\n",
    "        values: tuple\n",
    "            list of values to find entry to delete\n",
    "        Returns\n",
    "        ----------\n",
    "        True: if the entry was deleted\n",
    "        False: if the entry was not deleted\n",
    "        \"\"\"\n",
    "\n",
    "        cur = self.conn.cursor()\n",
    "        \n",
    "        # query for deleting with conditions\n",
    "        where_clause = sql.SQL(' AND ').join(\n",
    "            sql.SQL(\"{field} = %s\").format(field=sql.Identifier(field))\n",
    "            for field in fields\n",
    "        )\n",
    "        query = sql.SQL(\"\"\"\n",
    "        DELETE FROM {table}\n",
    "        WHERE {where_clause}\n",
    "        \"\"\").format(\n",
    "            table=sql.Identifier(table_name),\n",
    "            where_clause=where_clause\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            cur.execute(query, values)\n",
    "            self.conn.commit()\n",
    "            print('Deleted ' + str(values) + ' from ' + str(table_name)) # Logging to stdout\n",
    "        except Exception as err:\n",
    "            self.print_psycopg2_exception(err)\n",
    "            self.conn.rollback()\n",
    "            return False\n",
    "        cur.close()\n",
    "        return True\n",
    "\n",
    "    def get_fields(self, table_name):\n",
    "        \"\"\"\n",
    "        Gets the list of fields of the database table\n",
    "\n",
    "        ...\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        table_name: str\n",
    "            name of the database table to get fields from\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        column_names: list or None\n",
    "            returns a mutable object of the list of table fields or None if an error occurred\n",
    "        \"\"\"\n",
    "        cur = self.conn.cursor()\n",
    "        # Execute a simple SELECT query\n",
    "        try:\n",
    "            cur.execute(sql.SQL(\"SELECT * FROM {table} LIMIT 0\").format(\n",
    "                table=sql.Identifier(table_name)\n",
    "            ))\n",
    "            column_names = [desc[0] for desc in cur.description]\n",
    "        except Exception as err:\n",
    "            self.print_psycopg2_exception(err)\n",
    "            self.conn.rollback()\n",
    "            return None\n",
    "        cur.close()\n",
    "        return column_names\n",
    "\n",
    "    def get_table_desc(self, table_name):\n",
    "        \"\"\"\n",
    "        Gets the description of the datbaase table as a mutable object of columns where the first element is the name of the column and the second is the type code\n",
    "\n",
    "        ...\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        table_name: str\n",
    "            name of the database table to get fields from\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        descriptions: list or None\n",
    "            returns a mutable object of the description of the table's fields or None if an error occurred\n",
    "        \"\"\"\n",
    "        cur = self.conn.cursor()\n",
    "        # Execute a simple SELECT query\n",
    "        try:\n",
    "            cur.execute(sql.SQL(\"SELECT * FROM {table} LIMIT 0\").format(\n",
    "                table=sql.Identifier(table_name)\n",
    "            ))\n",
    "        except Exception as err:\n",
    "            self.print_psycopg2_exception(err)\n",
    "            self.conn.rollback()\n",
    "            return None\n",
    "        cur.close()\n",
    "        return cur.description\n",
    "\n",
    "    def insert_dataframe(self, table_name, df):\n",
    "        \"\"\"\n",
    "        Inserts a pandas dataframe as a series of INSERT statements into specified database table\n",
    "        Used when extracting data from a CSV file\n",
    "        Could also be used for general purposes such as having a pandas dataframe from any source\n",
    "        ...\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        table_name: str\n",
    "            name of the database table to insert entries into\n",
    "        df: dataframe\n",
    "            pandas dataframe to insert all entries from\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        True: if the dataframe was inserted\n",
    "        False: if the dataframe was not inserted\n",
    "        \"\"\"\n",
    "\n",
    "        cur = self.conn.cursor()\n",
    "        columns = list(df.columns)\n",
    "        values = [tuple(row) for row in df.itertuples(index=False, name=None)]\n",
    "        print('Inserting ' + str(len(values)) + ' to ' + table_name) # Logging to stdout\n",
    "        for value in values:\n",
    "            self.create_entry(table_name, tuple(columns), tuple(value))\n",
    "        print('Dataframe insertion to ' + table_name + ' complete.') # Logging to stdout\n",
    "        cur.close()\n",
    "\n",
    "    def execute_query(self, query):\n",
    "        cur = self.conn.cursor()\n",
    "        try:\n",
    "            cur.execute(query)\n",
    "            print(\"query executed\")\n",
    "            self.conn.commit()\n",
    "        except Exception as err:\n",
    "            self.print_psycopg2_exception(err)\n",
    "            self.conn.rollback()\n",
    "            return False\n",
    "            \n",
    "        cur.close()\n",
    "        return True\n",
    "\n",
    "    def print_psycopg2_exception(self, err):\n",
    "        \"\"\"\n",
    "        Prints the error obtained from handling database functions with psycopg2\n",
    "        ...\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        err: Exception\n",
    "            error to obtain details from\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        None\n",
    "        \"\"\"\n",
    "\n",
    "        err_type, err_obj, traceback = sys.exc_info()\n",
    "        line_num = traceback.tb_lineno\n",
    "        print (\"\\npsycopg2 ERROR:\", err, \"on line number:\", line_num)\n",
    "        print (\"psycopg2 traceback:\", traceback, \"-- type:\", err_type)\n",
    "        print (\"\\nextensions.Diagnostics:\", err.diag)\n",
    "        print (\"pgerror:\", err.pgerror)\n",
    "        print (\"pgcode:\", err.pgcode, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database manager has connected to health_tracking\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "dbManager = DatabaseManager(os.getenv('user'), os.getenv('dbname'), os.getenv('password'), os.getenv('host'), os.getenv('port'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Servings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query executed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS servings (\n",
    "    day                     TEXT NOT NULL,\n",
    "    \\\"group\\\"                   TEXT,\n",
    "    food_name               TEXT NOT NULL,\n",
    "    amount                  TEXT NOT NULL,\n",
    "    energy_kcal             FLOAT,\n",
    "    alcohol_g               FLOAT,\n",
    "    caffeine_mg             FLOAT,\n",
    "    water_g                 FLOAT,\n",
    "    b1_thiamine_mg          FLOAT,\n",
    "    b2_riboflavin_mg        FLOAT,\n",
    "    b3_niacin_mg            FLOAT,\n",
    "    b5_pantothenic_acid_mg  FLOAT,\n",
    "    b6_pyridoxine_mg        FLOAT,\n",
    "    b12_cobalamin_g         FLOAT,\n",
    "    folate_g                FLOAT,\n",
    "    vitamin_a_g             FLOAT,\n",
    "    vitamin_c_mg            FLOAT,\n",
    "    vitamin_d_iu            FLOAT,\n",
    "    vitamin_e_mg            FLOAT,\n",
    "    vitamin_k_g             FLOAT,\n",
    "    calcium_mg              FLOAT,\n",
    "    copper_mg               FLOAT,\n",
    "    iron_mg                 FLOAT,\n",
    "    magnesium_mg            FLOAT,\n",
    "    manganese_mg            FLOAT,\n",
    "    phosphorus_mg           FLOAT,\n",
    "    potassium_mg            FLOAT,\n",
    "    selenium_g              FLOAT,\n",
    "    sodium_mg               FLOAT,\n",
    "    zinc_mg                 FLOAT,\n",
    "    carbs_g                 FLOAT,\n",
    "    fiber_g                 FLOAT,\n",
    "    starch_g                FLOAT,\n",
    "    sugars_g                FLOAT,\n",
    "    added_sugars_g          FLOAT,\n",
    "    net_carbs_g             FLOAT,\n",
    "    fat_g                   FLOAT,\n",
    "    cholesterol_mg          FLOAT,\n",
    "    monounsaturated_g       FLOAT,\n",
    "    polyunsaturated_g       FLOAT,\n",
    "    saturated_g             FLOAT,\n",
    "    transfats_g             FLOAT,\n",
    "    omega3_g                FLOAT,\n",
    "    omega6_g                FLOAT,\n",
    "    cystine_g               FLOAT,\n",
    "    histidine_g             FLOAT,\n",
    "    isoleucine_g            FLOAT,\n",
    "    leucine_g               FLOAT,\n",
    "    lysine_g                FLOAT,\n",
    "    methionine_g            FLOAT,\n",
    "    phenylalanine_g         FLOAT,\n",
    "    protein_g               FLOAT,\n",
    "    threonine_g             FLOAT,\n",
    "    tryptophan_g            FLOAT,\n",
    "    tyrosine_g              FLOAT,\n",
    "    valine_g                FLOAT,\n",
    "    category                TEXT\n",
    ")\n",
    "\"\"\"\n",
    "dbManager.execute_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biometrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query executed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS biometrics (\n",
    "    day     TEXT NOT NULL,\n",
    "    \"group\" TEXT NOT NULL,\n",
    "    metric  TEXT NOT NULL,\n",
    "    unit    TEXT NOT NULL,\n",
    "    amount  FLOAT NOT NULL\n",
    ")\n",
    "\"\"\"\n",
    "dbManager.execute_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query executed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "CREATE TABLE dailysummary (\n",
    "    date                        TEXT NOT NULL,\n",
    "    energy_kcal                 FLOAT NOT NULL,\n",
    "    alcohol_g                   FLOAT,\n",
    "    caffeine_mg                 FLOAT,\n",
    "    water_g                     FLOAT,\n",
    "    b1_thiamine_mg              FLOAT,\n",
    "    b2_riboflavin_mg            FLOAT,\n",
    "    b3_niacin_mg                FLOAT,\n",
    "    b5_pantothenic_acid_mg      FLOAT,\n",
    "    b6_pyridoxine_mg            FLOAT,\n",
    "    b12_cobalamin_g            FLOAT,\n",
    "    folate_g                   FLOAT,\n",
    "    vitamin_a_g                FLOAT,\n",
    "    vitamin_c_mg                FLOAT,\n",
    "    vitamin_d_iu                FLOAT,\n",
    "    vitamin_e_mg                FLOAT,\n",
    "    vitamin_k_g                FLOAT,\n",
    "    calcium_mg                  FLOAT,\n",
    "    copper_mg                   FLOAT,\n",
    "    iron_mg                     FLOAT,\n",
    "    magnesium_mg                FLOAT,\n",
    "    manganese_mg                FLOAT,\n",
    "    phosphorus_mg               FLOAT,\n",
    "    potassium_mg                FLOAT,\n",
    "    selenium_g                 FLOAT,\n",
    "    sodium_mg                   FLOAT,\n",
    "    zinc_mg                     FLOAT,\n",
    "    carbs_g                     FLOAT,\n",
    "    fiber_g                     FLOAT,\n",
    "    starch_g                    FLOAT,\n",
    "    sugars_g                    FLOAT,\n",
    "    added_sugars_g              FLOAT,\n",
    "    net_carbs_g                 FLOAT,\n",
    "    fat_g                       FLOAT,\n",
    "    cholesterol_mg              FLOAT,\n",
    "    monounsaturated_g           FLOAT,\n",
    "    polyunsaturated_g           FLOAT,\n",
    "    saturated_g                 FLOAT,\n",
    "    transfats_g                FLOAT,\n",
    "    omega3_g                    FLOAT,\n",
    "    omega6_g                    FLOAT,\n",
    "    cystine_g                   FLOAT,\n",
    "    histidine_g                 FLOAT,\n",
    "    isoleucine_g                FLOAT,\n",
    "    leucine_g                   FLOAT,\n",
    "    lysine_g                    FLOAT,\n",
    "    methionine_g                FLOAT,\n",
    "    phenylalanine_g             FLOAT,\n",
    "    protein_g                   FLOAT,\n",
    "    threonine_g                 FLOAT,\n",
    "    tryptophan_g                FLOAT,\n",
    "    tyrosine_g                  FLOAT,\n",
    "    valine_g                    FLOAT,\n",
    "    completed                   BOOLEAN\n",
    ")\n",
    "\"\"\"\n",
    "dbManager.execute_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'category'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32me:\\Code\\data_blog\\blog_files\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'category'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m values:\n\u001b[0;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(value)\n\u001b[1;32m----> 4\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m     new_column_names \u001b[38;5;241m=\u001b[39m [transform_column_name(col) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns]\n",
      "File \u001b[1;32me:\\Code\\data_blog\\blog_files\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32me:\\Code\\data_blog\\blog_files\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'category'"
     ]
    }
   ],
   "source": [
    "for key, values in file_categories.items():\n",
    "    for value in values:\n",
    "        df = pd.read_csv(value)\n",
    "        if 'category' in df.columns:\n",
    "            df['category'] = df['category'].fillna(\"\")\n",
    "        df = df.fillna(0)\n",
    "        new_column_names = [transform_column_name(col) for col in df.columns]\n",
    "        df.columns = new_column_names\n",
    "        dbManager.insert_dataframe(table_name=key, df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query executed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "DROP TABLE dailysummary\n",
    "\"\"\"\n",
    "dbManager.execute_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query executed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "DROP TABLE servings\n",
    "\"\"\"\n",
    "dbManager.execute_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 0 entries from servings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['day',\n",
       "  'group',\n",
       "  'food_name',\n",
       "  'amount',\n",
       "  'energy_kcal',\n",
       "  'alcohol_g',\n",
       "  'caffeine_mg',\n",
       "  'water_g',\n",
       "  'b1_thiamine_mg',\n",
       "  'b2_riboflavin_mg',\n",
       "  'b3_niacin_mg',\n",
       "  'b5_pantothenic_acid_mg',\n",
       "  'b6_pyridoxine_mg',\n",
       "  'b12_cobalamin_g',\n",
       "  'folate_g',\n",
       "  'vitamin_a_g',\n",
       "  'vitamin_c_mg',\n",
       "  'vitamin_d_iu',\n",
       "  'vitamin_e_mg',\n",
       "  'vitamin_k_g',\n",
       "  'calcium_mg',\n",
       "  'copper_mg',\n",
       "  'iron_mg',\n",
       "  'magnesium_mg',\n",
       "  'manganese_mg',\n",
       "  'phosphorus_mg',\n",
       "  'potassium_mg',\n",
       "  'selenium_g',\n",
       "  'sodium_mg',\n",
       "  'zinc_mg',\n",
       "  'carbs_g',\n",
       "  'fiber_g',\n",
       "  'starch_g',\n",
       "  'sugars_g',\n",
       "  'added_sugars_g',\n",
       "  'net_carbs_g',\n",
       "  'fat_g',\n",
       "  'cholesterol_mg',\n",
       "  'monounsaturated_g',\n",
       "  'polyunsaturated_g',\n",
       "  'saturated_g',\n",
       "  'transfats_g',\n",
       "  'omega3_g',\n",
       "  'omega6_g',\n",
       "  'cystine_g',\n",
       "  'histidine_g',\n",
       "  'isoleucine_g',\n",
       "  'leucine_g',\n",
       "  'lysine_g',\n",
       "  'methionine_g',\n",
       "  'phenylalanine_g',\n",
       "  'protein_g',\n",
       "  'threonine_g',\n",
       "  'tryptophan_g',\n",
       "  'tyrosine_g',\n",
       "  'valine_g',\n",
       "  'category'],\n",
       " [])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbManager.get_table(\"servings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbManager.get_value()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
